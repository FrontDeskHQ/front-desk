# Hybrid Search Algorithm for Thread Similarity

This document explains how the `findSimilarThreadsById` function finds similar threads using a hybrid search approach that combines **vector similarity** (semantic meaning) with **keyword matching** (exact terms).

## Algorithm Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INPUT: Thread ID                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. RETRIEVE SOURCE THREAD DATA                                         â”‚
â”‚     â€¢ Fetch embedding vector from indexed chunks                        â”‚
â”‚     â€¢ Fetch extracted keywords (if available)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. HYBRID SEARCH (Typesense)                                           â”‚
â”‚     â€¢ Vector query: semantic similarity using embeddings                â”‚
â”‚     â€¢ Text query: keyword matching on content/keywords fields           â”‚
â”‚     â€¢ Combined via Rank Fusion with alpha parameter                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. CUTOFF FILTER                                                       â”‚
â”‚     â€¢ Remove chunks with score < cutoffScore (default: 0.3)             â”‚
â”‚     â€¢ Reduces noise from irrelevant matches                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. AGGREGATION BY THREAD                                               â”‚
â”‚     â€¢ Group chunks by threadId                                          â”‚
â”‚     â€¢ Calculate final score using weighted mean + multi-chunk bonus     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. OUTPUT: Ranked list of similar threads                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Step-by-Step Breakdown

### Step 1: Retrieve Source Thread Data

The algorithm first fetches the indexed data for the source thread:

```
Source Thread (thread_123)
    â”‚
    â”œâ”€â”€ Embedding Vector: [0.123, -0.456, 0.789, ...]  (768 dimensions)
    â”‚
    â””â”€â”€ Keywords: "authentication, login, OAuth, JWT, session"
```

**Debug output shows:**
```
âš™ï¸  Search Parameters (from real implementation):
    Keywords: "authentication, login, OAuth, JWT, session"
```

---

### Step 2: Hybrid Search

The search combines two approaches using Typesense's hybrid search:

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Source Thread     â”‚
                    â”‚   Embedding + KW    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚                               â”‚
              â–¼                               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  VECTOR SEARCH  â”‚             â”‚ KEYWORD SEARCH  â”‚
    â”‚                 â”‚             â”‚                 â”‚
    â”‚ Cosine distance â”‚             â”‚ BM25 ranking    â”‚
    â”‚ on embeddings   â”‚             â”‚ on keywords +   â”‚
    â”‚                 â”‚             â”‚ content fields  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                               â”‚
              â”‚      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
              â””â”€â”€â”€â”€â”€â–ºâ”‚ RANK FUSION   â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚               â”‚
                     â”‚ alpha = 0.7   â”‚
                     â”‚ (70% vector,  â”‚
                     â”‚  30% keyword) â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
                     Combined Score
                  (rank_fusion_score)
```

**Alpha Parameter:**
- `alpha = 1.0` â†’ Pure vector search (semantic only)
- `alpha = 0.0` â†’ Pure keyword search (exact terms only)
- `alpha = 0.7` â†’ 70% vector weight, 30% keyword weight (default)

**Debug output shows:**
```
âš™ï¸  Search Parameters (from real implementation):
    Alpha: 0.7 (70% vector, 30% keyword)

ğŸ” Score Components:
    Hybrid search (rank_fusion): 40 chunks
    Keyword/text search: 40 chunks
      Avg text_match score: 1234567.5
      Avg tokens matched: 3.2
    Vector similarity: 40 chunks
      Avg vector score: 0.623
```

---

### Step 3: Cutoff Filter

Low-scoring chunks are removed to reduce noise:

```
All Retrieved Chunks (k=40)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chunk A: score=0.85  âœ“ KEEP                                   â”‚
â”‚  Chunk B: score=0.72  âœ“ KEEP                                   â”‚
â”‚  Chunk C: score=0.45  âœ“ KEEP                                   â”‚
â”‚  Chunk D: score=0.28  âœ— CUT (below 0.3 cutoff)                 â”‚
â”‚  Chunk E: score=0.15  âœ— CUT (below 0.3 cutoff)                 â”‚
â”‚  ...                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
   Filtered Chunks
```

**Debug output shows:**
```
ğŸ“Š Scoring Breakdown:
  Total chunks found: 40
  Chunks after cutoff (>= 0.3): 25
  Chunks cut out (< 0.3): 15

âŒ Cut Out Chunks (score < 0.3):
    - thread_456 (chunk 0): 0.2845 [rank_fusion=0.2845, text_match=12345, tokens=2, vector_dist=0.4521]
    - thread_789 (chunk 1): 0.2234 [rank_fusion=0.2234, text_match=8901, tokens=1, vector_dist=0.5123]
```

**Why chunks get cut out:**
| Reason | Symptom in Debug |
|--------|------------------|
| Semantically unrelated | Low `vector_score` (< 0.5) |
| No keyword overlap | Low `text_match`, `tokens=0` |
| Partial relevance | Medium scores in both, but combined still < 0.3 |

---

### Step 4: Aggregation by Thread

Multiple chunks from the same thread are combined into a single score:

```
Filtered Chunks                         Aggregated Threads
                                        
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ thread_A, chunk_0    â”‚               â”‚ thread_A             â”‚
â”‚   score: 0.85        â”‚â”€â”€â”            â”‚   chunks: 3          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚            â”‚   scores: [0.85,     â”‚
â”‚ thread_A, chunk_1    â”‚â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚            0.72,     â”‚
â”‚   score: 0.72        â”‚  â”‚            â”‚            0.65]     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚            â”‚   mean: 0.740        â”‚
â”‚ thread_A, chunk_2    â”‚â”€â”€â”˜            â”‚   bonus: 0.15        â”‚
â”‚   score: 0.65        â”‚               â”‚   final: 0.890       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ thread_B, chunk_0    â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   score: 0.78        â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚ thread_B             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               â”‚   chunks: 1          â”‚
â”‚ thread_C, chunk_0    â”‚               â”‚   scores: [0.78]     â”‚
â”‚   score: 0.55        â”‚â”€â”€â”            â”‚   mean: 0.780        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚            â”‚   bonus: 0.05        â”‚
â”‚ thread_C, chunk_1    â”‚â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   final: 0.830       â”‚
â”‚   score: 0.48        â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                       â”‚ thread_C             â”‚
                                       â”‚   chunks: 2          â”‚
                                       â”‚   scores: [0.55,     â”‚
                                       â”‚            0.48]     â”‚
                                       â”‚   mean: 0.515        â”‚
                                       â”‚   bonus: 0.10        â”‚
                                       â”‚   final: 0.615       â”‚
                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Aggregation Formula (Weighted Mean):**
```
mean_score = sum(chunk_scores) / count(chunks)
bonus = min(count(chunks) * 0.05, 0.15)    // Max bonus: 0.15
final_score = min(mean_score + bonus, 1.0)  // Capped at 1.0
```

**Why multi-chunk bonus?**
- Threads with multiple matching chunks are more likely to be genuinely similar
- Bonus rewards breadth of similarity (multiple relevant sections)
- Capped at 0.15 to prevent over-weighting

**Debug output shows:**
```
âœ… Final Thread Scores (with aggregation details):

    thread_auth_001 [EXPECTED âœ“]
      Final Score: 0.8900
      Matching Chunks: 3
      Chunk Breakdown:
        - Chunk 0: 0.850 [fusion=0.850, text=1234567, (5 tokens), vector=0.812]
        - Chunk 1: 0.720 [fusion=0.720, text=987654, (3 tokens), vector=0.756]
        - Chunk 2: 0.650 [fusion=0.650, text=654321, (2 tokens), vector=0.698]
      Aggregated Scores: [0.850, 0.720, 0.650]
      Aggregation: mean(0.850, 0.720, 0.650) = 0.740 + bonus(0.150) = 0.890
```

---

## Understanding Debug Output

### Search Parameters Block

```
âš™ï¸  Search Parameters (from real implementation):
    Alpha: 0.7 (70% vector, 30% keyword)     â† How vector/keyword are weighted
    Cutoff Score: 0.3                         â† Minimum chunk score to keep
    Use Weighted Mean: true                   â† Aggregation method
    Limit: 10, k: 40                          â† Output limit, search breadth
    Keywords: "auth, login, OAuth..."         â† Keywords used for text search
```

### Scoring Breakdown Block

```
ğŸ“Š Scoring Breakdown:
  Total chunks found: 40        â† Raw results from Typesense
  Chunks after cutoff: 25       â† After removing low scores
  Chunks cut out: 15            â† Filtered out as noise
```

### Score Components Block

```
ğŸ” Score Components:
    Hybrid search (rank_fusion): 40 chunks
    Keyword/text search: 40 chunks
      Avg text_match score: 1234567.5    â† BM25-style score (higher = more keyword matches)
      Avg tokens matched: 3.2            â† Avg keywords matched per chunk
    Vector similarity: 40 chunks
      Avg vector score: 0.623            â† 1 - vector_distance (0-1 scale)
```

### Cut Out Chunks Block

```
âŒ Cut Out Chunks (score < 0.3):
    - thread_456 (chunk 0): 0.2845 [rank_fusion=0.2845, text_match=12345, tokens=2, vector_dist=0.4521]
                            â”‚       â”‚                   â”‚               â”‚          â”‚
                            â”‚       â”‚                   â”‚               â”‚          â””â”€ Cosine distance (lower=closer)
                            â”‚       â”‚                   â”‚               â””â”€ Keywords matched
                            â”‚       â”‚                   â””â”€ BM25 text score
                            â”‚       â””â”€ Combined hybrid score
                            â””â”€ Final score (same as rank_fusion here)
```

### Thread Details Block

```
âœ… Final Thread Scores (with aggregation details):

    thread_auth_001 [EXPECTED âœ“]           â† Marker shows if thread was expected
      Final Score: 0.8900                  â† Score after aggregation
      Matching Chunks: 3                   â† How many chunks contributed
      Chunk Breakdown:
        - Chunk 0: 0.850 [fusion=0.850, text=1234567, (5 tokens), vector=0.812]
        - Chunk 1: 0.720 [...]
      Aggregated Scores: [0.850, 0.720, 0.650]
      Aggregation: mean(0.850, 0.720, 0.650) = 0.740 + bonus(0.150) = 0.890
                   â”‚                          â”‚       â”‚             â”‚
                   â”‚                          â”‚       â”‚             â””â”€ Final score
                   â”‚                          â”‚       â””â”€ Multi-chunk bonus
                   â”‚                          â””â”€ Average of chunk scores
                   â””â”€ Individual chunk scores
```

---

## Why Candidates Pass or Fail

### Common Pass Patterns

| Pattern | Debug Evidence |
|---------|---------------|
| **Strong semantic match** | High `vector_score` (> 0.7), multiple chunks pass cutoff |
| **Strong keyword match** | High `tokens_matched` (> 4), high `text_match` scores |
| **Broad relevance** | Multiple chunks from same thread, each with decent scores |

### Common Fail Patterns

| Pattern | Debug Evidence | Solution |
|---------|---------------|----------|
| **All chunks cut out** | Thread appears only in "Cut Out Chunks" section | Lower `cutoffScore` or improve indexing |
| **Low vector scores** | `vector_score` < 0.5 consistently | Content may be semantically different |
| **No keyword overlap** | `tokens_matched = 0` | Add more keywords during indexing |
| **Single weak chunk** | Only 1 chunk, low score, no bonus | Thread has limited relevant content |

### Debugging Checklist

1. **Is the expected thread in "Cut Out Chunks"?**
   - Yes â†’ Score is below cutoff, may need tuning
   - No â†’ Thread chunks weren't even retrieved

2. **What's the chunk breakdown?**
   - High vector, low text â†’ Semantic match, keyword mismatch
   - Low vector, high text â†’ Keyword match, semantic difference
   - Both low â†’ Genuinely dissimilar

3. **How many chunks matched?**
   - Many chunks â†’ Strong overall similarity
   - Few chunks â†’ Narrow similarity (specific topic only)

---

## Configuration Reference

| Parameter | Default | Description |
|-----------|---------|-------------|
| `alpha` | 0.7 | Vector vs keyword weight (0=all keyword, 1=all vector) |
| `cutoffScore` | 0.3 | Minimum chunk score to keep |
| `useWeightedMean` | true | Use mean+bonus vs max score |
| `limit` | 10 | Max threads to return |
| `k` | limit Ã— 4 | Chunks to retrieve before aggregation |

---

## Related Files

- [`thread-embeddings.ts`](../thread-embeddings.ts) - Main implementation with `findSimilarThreadsById`
- [`hybrid-search.eval.ts`](./hybrid-search.eval.ts) - Evaluation script that uses debug output
- [`fake-threads.json`](./fake-threads.json) - Test data with similarity groups
